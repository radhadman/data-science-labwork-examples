{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9: Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabrielm/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first work with some data about Carseat sales. One of the variables is 'Sales' and we are going to create a new binary variable 'High' that is True is 'Sales' is greater than 8 and False otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "      <th>High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price  ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120          0   42   \n",
       "1  11.22        111      48           16         260     83          1   65   \n",
       "2  10.06        113      35           10         269     80          2   59   \n",
       "3   7.40        117     100            4         466     97          2   55   \n",
       "4   4.15        141      64            3         340    128          0   38   \n",
       "\n",
       "   Education  Urban  US   High  \n",
       "0         17      1   1   True  \n",
       "1         10      1   1   True  \n",
       "2         12      1   1   True  \n",
       "3         14      1   1  False  \n",
       "4         13      1   0  False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Carseats.csv')\n",
    "df['High'] = df['Sales'] > 8 \n",
    "df.ShelveLoc = pd.factorize(df.ShelveLoc)[0]\n",
    "df.Urban = df.Urban.map({'No':0, 'Yes':1})\n",
    "df.US = df.US.map({'No':0, 'Yes':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will predict 'High' using the other features. This is a binary classification task. The predictor features (X) will include everything except 'Sales' and 'High.'\n",
    "\n",
    "It is probably obvious to you why we need to exclude 'High' (because it is the outcome variable we are trying to predict), but make sure you also understand why we need to remove 'Sales' from the features as well.\n",
    "\n",
    "We randomly select 50% of the data as training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Sales', 'High'], axis=1)\n",
    "y = df.High\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we are just using a multi-layer perceptron as a drop-in substitute for the other types of classifiers we have been using. \n",
    "\n",
    "Let's compare an MLP, a Perceptron, Logistic Regression, and  Gradient Boosting classifier (a classifier based on decision trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(10,10), max_iter=1000, activation='relu', random_state=1)\n",
    "perc = Perceptron(penalty='l1', random_state=1, max_iter=1000, shuffle=True)\n",
    "logreg = LogisticRegression()\n",
    "gb = GradientBoostingClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=1, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, y_train)\n",
    "perc.fit(X_train, y_train)\n",
    "logreg.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make predictions on the test set using each model, and show a confusion matrix for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_nn = nn.predict(X_test)\n",
    "preds_perc = perc.predict(X_test)\n",
    "preds_logreg = logreg.predict(X_test)\n",
    "preds_gb = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Neural Network:\n",
      "\n",
      "     No  Yes\n",
      "No   96   26\n",
      "Yes  23   55\n",
      "\n",
      "Accuracy is: 0.755\n"
     ]
    }
   ],
   "source": [
    "cm_nn = pd.DataFrame(confusion_matrix(y_test, preds_nn).T, index=['No', 'Yes'], columns=['No', 'Yes'])\n",
    "print(\"Using Neural Network:\\n\")\n",
    "print(cm_nn)\n",
    "\n",
    "tree_acc = accuracy_score(y_test, preds_nn)\n",
    "print('\\nAccuracy is: %s' % tree_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Perceptron:\n",
      "\n",
      "      No  Yes\n",
      "No   118   61\n",
      "Yes    1   20\n",
      "\n",
      "Accuracy is: 0.69\n"
     ]
    }
   ],
   "source": [
    "cm_perc = pd.DataFrame(confusion_matrix(y_test, preds_perc).T, index=['No', 'Yes'], columns=['No', 'Yes'])\n",
    "print(\"Using the Perceptron:\\n\")\n",
    "print(cm_perc)\n",
    "\n",
    "tree_acc = accuracy_score(y_test, preds_perc)\n",
    "print('\\nAccuracy is: %s' % tree_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression:\n",
      "\n",
      "      No  Yes\n",
      "No   103   26\n",
      "Yes   16   55\n",
      "\n",
      "Accuracy is: 0.79\n"
     ]
    }
   ],
   "source": [
    "cm_logreg = pd.DataFrame(confusion_matrix(y_test, preds_logreg).T, index=['No', 'Yes'], columns=['No', 'Yes'])\n",
    "print(\"Using Logistic Regression:\\n\")\n",
    "print(cm_logreg)\n",
    "\n",
    "tree_acc = accuracy_score(y_test, preds_logreg)\n",
    "print('\\nAccuracy is: %s' % tree_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression:\n",
      "\n",
      "      No  Yes\n",
      "No   103   23\n",
      "Yes   16   58\n",
      "\n",
      "Accuracy is: 0.805\n"
     ]
    }
   ],
   "source": [
    "cm_gb = pd.DataFrame(confusion_matrix(y_test, preds_gb).T, index=['No', 'Yes'], columns=['No', 'Yes'])\n",
    "print(\"Using Logistic Regression:\\n\")\n",
    "print(cm_gb)\n",
    "\n",
    "tree_acc = accuracy_score(y_test, preds_gb)\n",
    "print('\\nAccuracy is: %s' % tree_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, Logistic Regression and Gradient Boosting Trees perform the best. This isn't surprising, given that it's a small amount of data, and that we haven't tried to optimize the structure of the neural network.\n",
    "\n",
    "Tree-based models tend to work very well on these types of datasets.\n",
    "\n",
    "In the lab assignment, you will work with a different dataset and spend more time trying out different neural architectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment\n",
    "\n",
    "* Read in the Boston dataset. \n",
    "* This includes some socioeconomic data about neighbourhoods in Boston.\n",
    "* Create a new variable 'HighVal' that is True when 'medv' is greater than 20, and False otherwise.\n",
    "* You will be doing classification, to predict 'HighVal', i.e. whether a neighbourhood has high median home values.\n",
    "* The outcome variable is 'HighVal'.\n",
    "* The features are all of the other variables, except 'medv' and 'HighVal'. \n",
    "* Select 50% of the data as training data (using the train_test_split() function, as above). \n",
    "* Train three different Multi-Layer Perceptron classifiers on the training set. \n",
    "* * Try varying numbers of hidden layers. \n",
    "* * Try varying numbers of neurons in the hidden layers.\n",
    "* * Try a couple of activation functions. \n",
    "* Make predictions on the test set using each model, and calculate accuracy and show a confusion matrix for each model.\n",
    "* Compare these predictions with predictions from at least two other models.\n",
    "* * e.g. the Perceptron or Logistic Regression.\n",
    "\n",
    "__Submit your completed notebook via Blackboard.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
